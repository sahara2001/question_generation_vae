{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n",
      "109\n",
      "length 188\n",
      "<class 'numpy.int64'>\n",
      "WARNING:tensorflow:From /home1/shifangping/miniconda3/envs/vae/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 64)       12032       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_1 (GCNN)                   (None, 10, 64)       24576       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_2 (GCNN)                   (None, 10, 64)       24576       gcnn_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_3 (GCNN)                   (None, 10, 64)       24576       gcnn_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_4 (GCNN)                   (None, 10, 64)       24576       gcnn_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_5 (GCNN)                   (None, 10, 64)       24576       gcnn_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_6 (GCNN)                   (None, 10, 64)       24576       gcnn_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_7 (GCNN)                   (None, 10, 64)       24576       gcnn_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_8 (GCNN)                   (None, 10, 64)       24576       gcnn_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_9 (GCNN)                   (None, 10, 64)       24576       gcnn_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_10 (GCNN)                  (None, 10, 64)       24576       gcnn_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           gcnn_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4160        global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           4160        global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 64)           0           dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 640)          41600       lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 64)       0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gcnn_11 (GCNN)                  (None, 10, 64)       24576       reshape_1[0][0]                  \n",
      "                                                                 gcnn_11[0][0]                    \n",
      "                                                                 gcnn_11[1][0]                    \n",
      "                                                                 gcnn_11[2][0]                    \n",
      "                                                                 gcnn_11[3][0]                    \n",
      "                                                                 gcnn_11[4][0]                    \n",
      "                                                                 gcnn_11[5][0]                    \n",
      "                                                                 gcnn_11[6][0]                    \n",
      "                                                                 gcnn_11[7][0]                    \n",
      "                                                                 gcnn_11[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10, 188)      12220       gcnn_11[9][0]                    \n",
      "==================================================================================================\n",
      "Total params: 344,508\n",
      "Trainable params: 344,508\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /home1/shifangping/miniconda3/envs/vae/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home1/shifangping/miniconda3/envs/vae/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 113.9227\n",
      "b'          \\xe8\\xba\\xac\\xe9\\x9b\\x85\\xe5\\x8d\\xb1\\xe7\\xa2\\xa7\\xe6\\xa1\\xa5\\xef\\xbc\\x8c\\xe5\\xbe\\x97\\xe9\\xab\\x98\\xe5\\x8a\\xb3\\xe7\\xa6\\xbb\\xe7\\xbb\\xb3'\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 101.7549\n",
      "b'          \\xe5\\x89\\x8d\\xe6\\x89\\x80\\xe9\\xa6\\x99\\xe5\\xbf\\x83\\xe9\\x9b\\x85\\xef\\xbc\\x8c\\xe6\\x98\\x8e\\xe8\\xbf\\xb9\\xe5\\x80\\xa6\\xe9\\x98\\x81\\xe9\\x87\\x8d'\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 89.6315\n",
      "b'          \\xe7\\xa5\\x9e\\xe6\\xb7\\xb9\\xe8\\x8a\\xb3\\xe5\\xbd\\xa9\\xe4\\xb8\\x87\\xef\\xbc\\x8c\\xe5\\x8d\\xab\\xe5\\xbd\\xa9\\xe9\\x87\\x91\\xe5\\xbf\\x83\\xe6\\xb1\\xa0'\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 76.6958\n",
      "b'          \\xe6\\xb8\\x85\\xe5\\xaf\\xb8\\xe6\\xac\\xb9\\xe9\\xab\\x98\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe6\\xbe\\x84\\xe9\\xaa\\x8f\\xe7\\x8e\\xb3\\xe6\\x96\\x9c\\xe6\\x95\\xb7'\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 70.6061\n",
      "b'          \\xe6\\xae\\xbf\\xe5\\x8d\\xb7\\xe5\\x9d\\x9f\\xe6\\x95\\xa3\\xe6\\xa0\\x91\\xef\\xbc\\x8c\\xe7\\xad\\xb5\\xe6\\x98\\x8e\\xe5\\xa6\\x82\\xe7\\xbd\\x8d\\xe4\\xb8\\x87'\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 66.2879\n",
      "b'          \\xe6\\x91\\x87\\xe6\\x98\\xad\\xe7\\xb4\\xa0\\xe5\\x9d\\x9f\\xe9\\xab\\x98\\xef\\xbc\\x8c\\xe4\\xb8\\xba\\xe6\\x82\\xac\\xe8\\x80\\xbf\\xe6\\x95\\xb7\\xe5\\xbf\\x83'\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 63.5727\n",
      "b'          \\xe9\\x98\\xb4\\xe6\\xb8\\x85\\xe6\\xa0\\x91\\xe5\\x86\\x99\\xe4\\xba\\xad\\xef\\xbc\\x8c\\xe9\\xbe\\x99\\xe7\\x8e\\x89\\xe5\\xb0\\xba\\xe6\\x8e\\xa5\\xe7\\x8e\\x89'\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 60.0225\n",
      "b'          \\xe6\\xae\\xbf\\xe6\\x91\\x87\\xe6\\x95\\xb7\\xe6\\x88\\x92\\xe6\\x88\\x92\\xef\\xbc\\x8c\\xe5\\x8d\\xab\\xe4\\xba\\xad\\xe7\\x96\\x8f\\xe4\\xb9\\xb1\\xe5\\x87\\xa4'\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 58.2911\n",
      "b'          \\xe4\\xba\\xad\\xe6\\x88\\x92\\xe8\\xb5\\xb7\\xe6\\xb1\\x89\\xe4\\xbd\\x95\\xef\\xbc\\x8c\\xe5\\x9d\\x9f\\xe5\\xae\\xb4\\xe7\\x99\\xbe\\xe5\\xbf\\x83\\xe8\\xa7\\x88'\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 57.9203\n",
      "b'          \\xe8\\xb5\\x8f\\xe6\\xb1\\xa0\\xe6\\xae\\xbd\\xe9\\xa9\\xac\\xe9\\x9b\\x85\\xef\\xbc\\x8c\\xe5\\x8d\\xb3\\xe8\\xbe\\x99\\xe7\\x9b\\x88\\xe6\\xb1\\xa0\\xe9\\x87\\x91'\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 56.4884\n",
      "b'          \\xe6\\xb8\\x85\\xe5\\x80\\xa6\\xe9\\xa3\\x8e\\xe4\\xb8\\x87\\xe6\\x91\\x87\\xef\\xbc\\x8c\\xe6\\x82\\xa6\\xe5\\xb1\\x82\\xe6\\x96\\x9c\\xe5\\xaf\\xb9\\xe5\\x8d\\xb3'\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 55.7180\n",
      "b'          \\xe8\\xbe\\x99\\xe7\\xaf\\x86\\xe5\\x97\\xa3\\xe4\\xba\\xad\\xe5\\x8d\\x83\\xef\\xbc\\x8c\\xe7\\xad\\xb5\\xe5\\x89\\x8d\\xe8\\x8a\\xb3\\xe8\\xa7\\x82\\xe5\\x87\\x9d'\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 55.6061\n",
      "b'          \\xe5\\xbc\\xa6\\xe6\\xb7\\xb9\\xe9\\xbe\\x99\\xe7\\xa5\\x9e\\xe6\\xae\\xbf\\xef\\xbc\\x8c\\xe5\\xae\\xab\\xe5\\x9c\\x83\\xe5\\xbf\\x98\\xe5\\xbf\\x83\\xe5\\xb0\\xba'\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 54.5613\n",
      "b'          \\xe6\\xa0\\x91\\xe5\\xa6\\x82\\xe7\\x96\\x91\\xe9\\x85\\x92\\xe5\\x86\\x99\\xef\\xbc\\x8c\\xe8\\xaf\\x9a\\xe6\\xa1\\xa5\\xe5\\xb8\\xad\\xe7\\x95\\x99\\xe4\\xba\\xad'\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 53.8380\n",
      "b'          \\xe6\\x80\\x80\\xe6\\xac\\xb9\\xe7\\x83\\x9f\\xe6\\xb3\\x9b\\xe7\\xbd\\x97\\xef\\xbc\\x8c\\xe5\\xa3\\xb0\\xe4\\xba\\xba\\xe9\\x9b\\x89\\xe9\\x98\\xb3\\xe7\\x96\\x91'\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 52.9670\n",
      "b'          \\xe5\\x8c\\x96\\xe5\\xb3\\xb0\\xe9\\x95\\xbf\\xe9\\x95\\xbf\\xe5\\xbf\\x98\\xef\\xbc\\x8c\\xe7\\xaf\\x86\\xe8\\xaf\\x9a\\xe5\\xa6\\x82\\xe4\\xba\\xba\\xe7\\xa7\\x91'\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 52.6917\n",
      "b'          \\xe6\\x85\\x8e\\xe6\\xae\\xbf\\xe7\\x91\\xb6\\xe7\\xbd\\x97\\xe6\\x95\\xb7\\xef\\xbc\\x8c\\xe5\\xaf\\x9f\\xe5\\x88\\x91\\xe4\\xb8\\x87\\xe6\\x81\\xb6\\xe6\\x82\\xac'\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 51.2948\n",
      "b'          \\xe7\\x9a\\x8e\\xe5\\xbf\\x98\\xe6\\x95\\xa3\\xe7\\xa5\\x9e\\xe5\\x93\\x8d\\xef\\xbc\\x8c\\xe5\\xaf\\xb9\\xe5\\x88\\x91\\xe6\\xb7\\xb9\\xe5\\xbf\\x83\\xe4\\xb9\\x83'\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 51.2549\n",
      "b'          \\xe9\\x9f\\xb5\\xe8\\xb5\\xb7\\xe8\\x8d\\xa1\\xe6\\x98\\x8e\\xe7\\x96\\x8f\\xef\\xbc\\x8c\\xe6\\xae\\xbd\\xe6\\xad\\xa4\\xe4\\xba\\xad\\xe6\\x9c\\x88\\xe7\\x8e\\x89'\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 50.8623\n",
      "b'          \\xe9\\x9b\\x95\\xe8\\xb5\\x8f\\xe5\\xa3\\xb0\\xe7\\x99\\xbe\\xe8\\x82\\x86\\xef\\xbc\\x8c\\xe6\\x9c\\x88\\xe5\\x8a\\xb3\\xe8\\xbd\\xbb\\xe9\\x85\\x92\\xe6\\x96\\xb9'\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 49.7218\n",
      "b'          \\xe6\\x95\\xa3\\xe9\\x9b\\x85\\xe6\\x8a\\x9a\\xe7\\xa7\\x91\\xe6\\x88\\x92\\xef\\xbc\\x8c\\xe4\\xb8\\xba\\xe4\\xb8\\xbe\\xe5\\x8a\\xb3\\xe5\\x88\\x91\\xe9\\x9b\\x89'\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 48.8190\n",
      "b'          \\xe7\\x83\\x9f\\xe7\\x95\\x99\\xe6\\x80\\xa5\\xe6\\xa1\\xa5\\xe6\\x80\\x80\\xef\\xbc\\x8c\\xe5\\xbf\\x85\\xe5\\x93\\x8d\\xe7\\xa2\\xa7\\xe9\\xa6\\x80\\xe9\\x98\\xb4'\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 47.7262\n",
      "b'          \\xe5\\xb3\\xb0\\xe5\\x93\\x8d\\xe5\\xaf\\xbb\\xe4\\xb9\\xb1\\xe7\\x91\\x81\\xef\\xbc\\x8c\\xe5\\x9d\\x9f\\xe4\\xba\\x91\\xe9\\x87\\x91\\xe5\\xbe\\x80\\xe6\\x96\\xb9'\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 46.4128\n",
      "b'          \\xe5\\xb8\\xad\\xe8\\xbf\\xb9\\xe5\\xbd\\xa2\\xe9\\xa6\\x80\\xe8\\xbf\\xb9\\xef\\xbc\\x8c\\xe6\\xae\\xbf\\xe9\\xa9\\xac\\xe5\\x8a\\xbf\\xe6\\xa1\\xa5\\xe6\\x9c\\x88'\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 45.0259\n",
      "b'          \\xe5\\xbe\\x80\\xe8\\xb5\\x8f\\xe6\\xb5\\x81\\xe6\\x95\\xa3\\xe5\\x93\\x8d\\xef\\xbc\\x8c\\xe5\\x8a\\xb3\\xe6\\x8a\\x9a\\xe9\\x9f\\xb3\\xe7\\x8e\\x89\\xe5\\xbe\\x80'\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 42.8698\n",
      "b'          \\xe5\\xbe\\x97\\xe8\\x8a\\xb3\\xe6\\x88\\x92\\xe6\\x82\\xac\\xe9\\x9b\\x95\\xef\\xbc\\x8c\\xe6\\xa1\\xa5\\xe9\\x9b\\xaa\\xe6\\x97\\xa0\\xe6\\x96\\x9c\\xe5\\xb1\\x82'\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 41.1706\n",
      "b'          \\xe9\\xa3\\x8e\\xe4\\xb8\\xba\\xe8\\xbf\\xb9\\xe5\\xbd\\xa9\\xe6\\x97\\xa2\\xef\\xbc\\x8c\\xe6\\x91\\x87\\xe5\\xaf\\xbb\\xe5\\xb9\\xbf\\xe7\\x8e\\xb3\\xe5\\xb2\\x82'\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 38.9294\n",
      "b'          \\xe4\\xbd\\x95\\xe5\\x89\\x8d\\xe7\\x96\\x91\\xe5\\xbf\\x83\\xe5\\x85\\xb0\\xef\\xbc\\x8c\\xe7\\x91\\x81\\xe7\\xbb\\xae\\xe8\\xbf\\xb9\\xe6\\xb7\\xb3\\xe7\\x8e\\x89'\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 37.9328\n",
      "b'          \\xe5\\xae\\xab\\xe5\\xbd\\xa9\\xe5\\x97\\xa3\\xe5\\x8a\\xbf\\xe4\\xb8\\xba\\xef\\xbc\\x8c\\xe7\\x99\\xbe\\xe4\\xb8\\xbe\\xe6\\x80\\xa5\\xe5\\xbf\\x83\\xe9\\x80\\x9a'\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 35.9311\n",
      "b'          \\xe9\\x9b\\x85\\xe5\\xa3\\xb0\\xe9\\x87\\x91\\xe8\\xbd\\xbb\\xe9\\x98\\x81\\xef\\xbc\\x8c\\xe4\\xba\\xba\\xe5\\xaf\\xb9\\xe6\\x96\\x9c\\xe5\\x8d\\xb1\\xe5\\xbe\\x80'\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 34.0616\n",
      "b'          \\xe5\\x89\\x8d\\xe6\\xad\\xa4\\xe9\\x9f\\xb3\\xe6\\x80\\x80\\xe8\\xaf\\x9a\\xef\\xbc\\x8c\\xe9\\x9f\\xb3\\xe5\\x89\\x8d\\xe5\\x80\\xa6\\xe9\\xbe\\x99\\xe5\\x8c\\xa3'\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 33.2075\n",
      "b'          \\xe6\\xae\\xbf\\xe5\\x85\\xb0\\xe5\\xbf\\x98\\xe7\\x95\\x99\\xe5\\x85\\xb0\\xef\\xbc\\x8c\\xe7\\xa7\\x91\\xe4\\xb8\\x87\\xe6\\xb1\\xbe\\xe6\\xb1\\xbe\\xe7\\x96\\x8f'\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 30.8171\n",
      "b'          \\xe5\\x93\\x8d\\xe5\\x88\\x91\\xe5\\xbf\\x98\\xe5\\xa3\\xb0\\xe5\\x8e\\xbb\\xef\\xbc\\x8c\\xe5\\xb3\\xb0\\xe5\\xbe\\x85\\xe4\\xb8\\xba\\xe8\\xbf\\xb9\\xe7\\x99\\xbd'\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 29.5950\n",
      "b'          \\xe6\\xb8\\x85\\xe9\\x98\\xb4\\xe5\\xbf\\x83\\xe6\\xae\\xbd\\xe7\\xb4\\xa0\\xef\\xbc\\x8c\\xe5\\xaf\\xbb\\xe6\\x97\\xa5\\xe5\\xaf\\xbb\\xe6\\xad\\xa4\\xe6\\x80\\xa5'\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 28.0027\n",
      "b'          \\xe6\\x9b\\xb2\\xe7\\x83\\x9f\\xe6\\x89\\x80\\xe6\\x97\\xa5\\xe7\\x83\\x9f\\xef\\xbc\\x8c\\xe6\\x8a\\xab\\xe5\\x9b\\xbe\\xe6\\xac\\xa2\\xe5\\x85\\xb0\\xe6\\x8a\\xab'\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 26.6768\n",
      "b'          \\xe5\\xae\\xb4\\xe9\\xbe\\x99\\xe7\\xaf\\x86\\xe6\\x96\\xb9\\xe8\\xbf\\xb9\\xef\\xbc\\x8c\\xe5\\x88\\x9d\\xe4\\xba\\xad\\xe6\\xae\\xbf\\xe4\\xba\\xad\\xe5\\xa3\\xb0'\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 24.4212\n",
      "b'          \\xe5\\x8d\\xb1\\xe5\\x85\\xb0\\xe4\\xb8\\x87\\xe5\\x97\\xa3\\xe8\\x8a\\xb3\\xef\\xbc\\x8c\\xe8\\xb8\\xaa\\xe5\\x9b\\xbe\\xe8\\xbf\\xb9\\xe7\\x96\\x91\\xe9\\xab\\x98'\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 23.0130\n",
      "b'          \\xe5\\xa4\\x9a\\xe9\\x9b\\x89\\xe5\\xbd\\xa9\\xe5\\xaf\\xbb\\xe8\\xa7\\x88\\xef\\xbc\\x8c\\xe7\\x91\\x81\\xe6\\x96\\x9c\\xe9\\x98\\x99\\xe9\\xab\\x98\\xe8\\xbf\\xb9'\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 21.9223\n",
      "b'          \\xe5\\xaf\\xb8\\xe9\\xaa\\x8f\\xe5\\x86\\x99\\xe7\\xbb\\xae\\xe9\\x81\\x93\\xef\\xbc\\x8c\\xe7\\x99\\xbe\\xe5\\xbf\\x98\\xe5\\x85\\xb9\\xe6\\x97\\xa5\\xe6\\x98\\xad'\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 21.2931\n",
      "b'          \\xe4\\xb8\\xbe\\xe5\\x8d\\xb1\\xe8\\x8a\\xb3\\xe6\\xae\\xbd\\xe5\\x85\\xb0\\xef\\xbc\\x8c\\xe8\\xa7\\x82\\xe7\\xbb\\xae\\xe4\\xb9\\x83\\xe5\\xbf\\x83\\xe5\\xbf\\x97'\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 20.1618\n",
      "b'          \\xe5\\x9d\\x9f\\xe5\\x8d\\xb1\\xe5\\x86\\x99\\xe6\\x9c\\x88\\xe8\\xa7\\x82\\xef\\xbc\\x8c\\xe5\\x87\\xa4\\xe4\\xbd\\x95\\xe4\\xb8\\x87\\xe5\\x93\\x8d\\xe6\\x95\\xa3'\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 19.9273\n",
      "b'          \\xe5\\x96\\x84\\xe5\\xaf\\xbb\\xe6\\x96\\xb9\\xe5\\xbf\\x83\\xe8\\x99\\x9a\\xef\\xbc\\x8c\\xe7\\x9a\\x8e\\xe5\\x97\\xa3\\xe9\\xaa\\x8f\\xe5\\x8d\\xab\\xe6\\xac\\xa2'\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 17.5475\n",
      "b'          \\xe8\\xa7\\x82\\xe6\\x80\\xa5\\xe8\\xbd\\xbb\\xe7\\x9a\\x8e\\xe7\\x92\\xa7\\xef\\xbc\\x8c\\xe5\\x85\\xb9\\xe6\\xb1\\xa0\\xe6\\x96\\x9c\\xe8\\x8d\\xb7\\xe6\\x97\\xa2'\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 18.0748\n",
      "b'          \\xe6\\xac\\xa2\\xe7\\x9a\\x8e\\xe9\\x9b\\x95\\xe7\\xbb\\xae\\xe5\\xae\\xb4\\xef\\xbc\\x8c\\xe5\\xa3\\xb0\\xe4\\xb8\\xba\\xe5\\xbe\\x85\\xe6\\x96\\xb9\\xe9\\x9b\\xaa'\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 17.7350\n",
      "b'          \\xe6\\xae\\xbd\\xe6\\x96\\xb9\\xe4\\xb8\\xba\\xe7\\xa5\\x9e\\xe7\\xa2\\xa7\\xef\\xbc\\x8c\\xe6\\xb1\\xa0\\xe5\\x88\\x91\\xe5\\xbd\\xa9\\xe8\\x99\\x9a\\xe7\\x9a\\x8e'\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 18.0494\n",
      "b'          \\xe5\\xb2\\x82\\xe5\\x87\\xa4\\xe5\\xbf\\x83\\xe8\\xb5\\x8f\\xe5\\xbd\\xa9\\xef\\xbc\\x8c\\xe6\\x96\\xb9\\xe5\\x8d\\x83\\xe9\\xa3\\x8e\\xe6\\x96\\x9c\\xe9\\x99\\x88'\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 17.3438\n",
      "b'          \\xe7\\x94\\xb5\\xe4\\xb8\\x87\\xe8\\x90\\x8d\\xe5\\x85\\xb9\\xe4\\xba\\x91\\xef\\xbc\\x8c\\xe5\\xbc\\x93\\xe9\\xa3\\x8e\\xe9\\xaa\\x8f\\xe4\\xb8\\xba\\xe9\\x9b\\x89'\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 15.0257\n",
      "b'          \\xe4\\xb8\\x8a\\xe5\\xaf\\xb9\\xe6\\x88\\x92\\xe9\\x9b\\x95\\xe5\\xa4\\x84\\xef\\xbc\\x8c\\xe5\\xbf\\x85\\xe5\\x93\\x8d\\xe5\\x8d\\xab\\xe6\\xb1\\xa0\\xe8\\xbf\\xb9'\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 17.4389\n",
      "b'          \\xe8\\xb8\\xaa\\xe7\\xbb\\xae\\xe4\\xbb\\x99\\xe9\\xa3\\x8e\\xe5\\x85\\xb0\\xef\\xbc\\x8c\\xe8\\xa7\\x82\\xe9\\xa6\\x80\\xe4\\xb9\\x83\\xe6\\x98\\x8e\\xe9\\x98\\x85'\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 15.9368\n",
      "b'          \\xe5\\xa3\\xb0\\xe5\\xbd\\xa9\\xe6\\x96\\xb9\\xe5\\xbf\\x98\\xe5\\x85\\xb9\\xef\\xbc\\x8c\\xe9\\x87\\x8c\\xe8\\xa7\\x82\\xe5\\xaf\\x9f\\xe6\\xb2\\xb3\\xe5\\x89\\x8d'\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 15.1963\n",
      "b'          \\xe5\\xbe\\x97\\xe7\\xa7\\x91\\xe5\\x87\\x9d\\xe6\\xae\\xbd\\xe7\\xbd\\x8d\\xef\\xbc\\x8c\\xe5\\xbc\\x93\\xe9\\x98\\x85\\xe5\\xaf\\xb9\\xe4\\xb8\\x8a\\xe6\\x97\\xa2'\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 15.3136\n",
      "b'          \\xe7\\x94\\xb5\\xe6\\xa1\\xa5\\xe6\\xb1\\xa0\\xe8\\xbd\\xbb\\xe5\\xb9\\xbf\\xef\\xbc\\x8c\\xe6\\x8e\\xa5\\xe6\\x96\\x9c\\xe6\\xa1\\x88\\xe7\\x99\\xbe\\xe6\\x9c\\x88'\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 15.5153\n",
      "b'          \\xe4\\xb8\\x87\\xe9\\x85\\x92\\xe7\\xad\\xb5\\xe5\\x88\\x91\\xe4\\xb8\\xbe\\xef\\xbc\\x8c\\xe5\\x8d\\xab\\xe6\\x96\\xb9\\xe4\\xba\\xad\\xe7\\x92\\xa7\\xe5\\x8d\\xb1'\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 14.9762\n",
      "b'          \\xe8\\x82\\x86\\xe8\\xb5\\x8f\\xe5\\xbf\\x98\\xe5\\xbd\\xa2\\xe6\\x97\\xa5\\xef\\xbc\\x8c\\xe8\\xb8\\xaa\\xe4\\xb8\\xbe\\xe6\\x95\\xa3\\xe9\\x98\\x81\\xe6\\x98\\xad'\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 14.2282\n",
      "b'          \\xe6\\x98\\x8e\\xe8\\xa7\\x88\\xe4\\xba\\xad\\xe6\\xb7\\xb3\\xe6\\x98\\x8e\\xef\\xbc\\x8c\\xe6\\x96\\xb9\\xe5\\xbc\\xa6\\xe4\\xb9\\x83\\xe5\\xa6\\x82\\xe5\\xbf\\x83'\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.9057\n",
      "b'          \\xe5\\xb8\\xad\\xe5\\x8d\\xb1\\xe6\\x9c\\x88\\xe5\\x8d\\xb3\\xe8\\x8a\\xb3\\xef\\xbc\\x8c\\xe5\\x86\\x99\\xe4\\xbd\\x95\\xe4\\xb8\\x87\\xe5\\x86\\x99\\xe6\\xb8\\x85'\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.1935\n",
      "b'          \\xe7\\xa2\\xa7\\xe5\\xae\\xab\\xe5\\xb9\\xbf\\xe5\\x87\\xba\\xe9\\x98\\x85\\xef\\xbc\\x8c\\xe5\\x8d\\xb1\\xe7\\x8e\\xb3\\xe5\\x85\\xb9\\xe6\\xb1\\xa0\\xe7\\x99\\xbe'\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.5630\n",
      "b'          \\xe6\\xad\\xa4\\xe9\\x80\\x9a\\xe9\\x98\\x85\\xe5\\xbf\\x83\\xe8\\xbd\\xbb\\xef\\xbc\\x8c\\xe7\\xb4\\xa0\\xe4\\xb8\\x87\\xe8\\x90\\x8d\\xe5\\xbf\\x83\\xe7\\xa5\\x9e'\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 15.0113\n",
      "b'          \\xe6\\x95\\xa3\\xe8\\xb0\\x8f\\xe7\\x91\\x81\\xe6\\x96\\xb9\\xe8\\xb0\\x8f\\xef\\xbc\\x8c\\xe7\\x8e\\x89\\xe7\\xbb\\xb3\\xe7\\x9a\\x8e\\xe5\\x96\\x84\\xe4\\xb8\\xbe'\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 14.0559\n",
      "b'          \\xe9\\x9b\\xaa\\xe5\\xbf\\x98\\xe8\\xbd\\xbb\\xe9\\xa3\\x8e\\xe5\\xbf\\x98\\xef\\xbc\\x8c\\xe6\\x8e\\xa5\\xe5\\xae\\xb4\\xe5\\x85\\xb9\\xe9\\xa3\\x8e\\xe5\\xae\\xab'\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.4357\n",
      "b'          \\xe5\\xbe\\x80\\xe6\\xae\\xbf\\xe8\\x90\\x8d\\xe6\\x97\\xa0\\xe5\\x8c\\x96\\xef\\xbc\\x8c\\xe5\\xae\\xb4\\xe5\\xae\\xab\\xe7\\x91\\xb6\\xe7\\xaf\\x86\\xe5\\xbf\\x97'\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.2462\n",
      "b'          \\xe8\\xbe\\x99\\xe9\\xa9\\xac\\xe6\\x80\\xa5\\xe5\\x85\\xb0\\xe6\\xb2\\xb3\\xef\\xbc\\x8c\\xe7\\xad\\xb5\\xe5\\x87\\x9d\\xe7\\x99\\xbe\\xe8\\xb5\\xb7\\xe8\\x8d\\xb7'\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.9320\n",
      "b'          \\xe5\\x8d\\xb1\\xe8\\xb0\\x8f\\xe6\\x96\\xb9\\xe7\\x8e\\xb3\\xe7\\x94\\xb5\\xef\\xbc\\x8c\\xe7\\x9a\\x8e\\xe7\\x95\\x99\\xe7\\x96\\x91\\xe5\\x96\\x84\\xe5\\xa3\\xb0'\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 14.8057\n",
      "b'          \\xe7\\xbb\\xae\\xe6\\xae\\xbf\\xe9\\x9b\\x89\\xe6\\x97\\xa5\\xe9\\x98\\x85\\xef\\xbc\\x8c\\xe9\\xab\\x98\\xe5\\x9b\\xbe\\xe7\\xad\\xb5\\xe9\\xbe\\x99\\xe6\\x88\\x92'\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 13.5301\n",
      "b'          \\xe4\\xba\\xba\\xe5\\xb9\\xbf\\xe4\\xba\\xba\\xe9\\xaa\\x8f\\xe7\\x9b\\x88\\xef\\xbc\\x8c\\xe7\\x83\\x9f\\xe4\\xbd\\x95\\xe5\\xae\\xab\\xe5\\x87\\xba\\xe6\\x8a\\xab'\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 13.8666\n",
      "b'          \\xe9\\xa3\\x8e\\xe5\\xbe\\x80\\xe9\\x98\\x85\\xe9\\xa3\\x8e\\xe7\\x92\\xa7\\xef\\xbc\\x8c\\xe5\\xa4\\x84\\xe5\\x89\\x8d\\xe5\\xaf\\x9f\\xe8\\xa7\\x82\\xe5\\x87\\x9d'\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.8892\n",
      "b'          \\xe7\\xa2\\xa7\\xe8\\xb5\\x8f\\xe5\\x8d\\x83\\xe5\\x8d\\xab\\xe4\\xba\\xad\\xef\\xbc\\x8c\\xe7\\x91\\x81\\xe8\\x82\\x86\\xe4\\xb9\\x83\\xe7\\x91\\x81\\xe7\\x8e\\x89'\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.5356\n",
      "b'          \\xe6\\xa0\\x91\\xe4\\xbb\\x99\\xe6\\x80\\xa5\\xe9\\x97\\xb4\\xe6\\x97\\xa5\\xef\\xbc\\x8c\\xe5\\x86\\x99\\xe7\\x91\\x81\\xe6\\xb5\\x81\\xe6\\xb1\\xbe\\xe5\\x85\\xb8'\n",
      "Epoch 69/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 14.2188\n",
      "b'          \\xe6\\x9c\\x88\\xe5\\xbf\\x97\\xe4\\xb8\\x87\\xe5\\x85\\xb9\\xe7\\xad\\xb5\\xef\\xbc\\x8c\\xe4\\xb8\\xba\\xe6\\xb1\\xbe\\xe5\\x8d\\xb3\\xe6\\x91\\x87\\xe5\\xb3\\xb0'\n",
      "Epoch 70/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.5567\n",
      "b'          \\xe5\\xaf\\xb9\\xe8\\xa7\\x88\\xe4\\xb8\\x87\\xe5\\xb1\\x82\\xe5\\xbe\\x80\\xef\\xbc\\x8c\\xe8\\x82\\x86\\xe6\\x9c\\x88\\xe7\\x94\\xb5\\xe5\\xa4\\x84\\xe9\\x9f\\xb3'\n",
      "Epoch 71/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 11.8923\n",
      "b'          \\xe7\\xbe\\x8e\\xe4\\xbd\\x95\\xe6\\x9c\\x88\\xe5\\xbf\\x83\\xe7\\x95\\x99\\xef\\xbc\\x8c\\xe6\\xb8\\x85\\xe5\\xa4\\x84\\xe5\\xbf\\x98\\xe7\\x91\\xb6\\xe7\\x8e\\x89'\n",
      "Epoch 72/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.7522\n",
      "b'          \\xe6\\x8e\\xa5\\xe6\\xae\\xbf\\xe5\\x85\\xb8\\xe9\\x98\\x81\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe4\\xb9\\x83\\xe5\\x87\\xa4\\xe8\\xba\\xac\\xe9\\xaa\\x8f\\xe8\\x8d\\xb7'\n",
      "Epoch 73/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 14.0725\n",
      "b'          \\xe6\\xbe\\x84\\xe5\\x85\\xb8\\xe7\\xbb\\xae\\xe6\\xb1\\x89\\xe5\\xb1\\x82\\xef\\xbc\\x8c\\xe6\\xb7\\xb9\\xe7\\xb4\\xa0\\xe7\\x91\\xb6\\xe6\\xa1\\xa5\\xe5\\x80\\xa6'\n",
      "Epoch 74/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.1138\n",
      "b'          \\xe9\\x9f\\xb3\\xe7\\x8e\\xb3\\xe5\\x9d\\x9f\\xe6\\x91\\x87\\xe9\\x98\\x85\\xef\\xbc\\x8c\\xe5\\x8d\\xb7\\xe8\\xb5\\xb7\\xe8\\xa7\\x82\\xe5\\x8d\\xb1\\xe7\\x91\\x81'\n",
      "Epoch 75/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.8468\n",
      "b'          \\xe9\\x81\\x93\\xe8\\xbd\\xbb\\xe4\\xb8\\x87\\xe5\\x9d\\x9f\\xe6\\xad\\xa4\\xef\\xbc\\x8c\\xe4\\xba\\x91\\xe7\\x9b\\x88\\xe7\\x9a\\x8e\\xe9\\xa3\\x8e\\xe5\\xbf\\x97'\n",
      "Epoch 76/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.0710\n",
      "b'          \\xe6\\xa1\\xa5\\xe4\\xb9\\xb1\\xe4\\xba\\x91\\xe4\\xba\\xad\\xe7\\x83\\x9f\\xef\\xbc\\x8c\\xe7\\xbd\\x8d\\xe6\\x96\\xb9\\xe5\\xae\\xab\\xe8\\xbe\\x99\\xe7\\xbb\\xae'\n",
      "Epoch 77/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 14.2282\n",
      "b'          \\xe5\\xbf\\x98\\xe6\\xad\\xa4\\xe6\\x91\\x87\\xe5\\x87\\x9d\\xe5\\xae\\xab\\xef\\xbc\\x8c\\xe8\\xb5\\x8f\\xe5\\xbf\\x98\\xe5\\x85\\xb9\\xe5\\xa4\\x9a\\xe7\\xa2\\xa7'\n",
      "Epoch 78/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.3202\n",
      "b'          \\xe6\\xb8\\x85\\xe8\\xba\\xac\\xe5\\xb9\\xbf\\xe7\\xba\\xb3\\xe5\\xbf\\x98\\xef\\xbc\\x8c\\xe6\\x80\\x80\\xe7\\x8e\\xb3\\xe6\\xae\\xbf\\xe5\\xaf\\xbb\\xe5\\xb3\\xb0'\n",
      "Epoch 79/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 13.0805\n",
      "b'          \\xe8\\xb8\\xaa\\xe9\\x9b\\xaa\\xe6\\x80\\xa5\\xe5\\x85\\xb0\\xe5\\xaf\\xb9\\xef\\xbc\\x8c\\xe5\\x88\\x9d\\xe8\\xba\\xac\\xe6\\x81\\xb6\\xe4\\xb9\\x83\\xe9\\x98\\x99'\n",
      "Epoch 80/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.6239\n",
      "b'          \\xe7\\xbb\\xae\\xe6\\xb7\\xb9\\xe5\\x8d\\xb3\\xe9\\xab\\x98\\xe9\\xa9\\xac\\xef\\xbc\\x8c\\xe9\\x97\\xb4\\xe5\\xbd\\xa9\\xe8\\x82\\x86\\xe5\\x8e\\xbb\\xe4\\xb8\\xbe'\n",
      "Epoch 81/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.3899\n",
      "b'          \\xe7\\x9a\\x8e\\xe6\\xb1\\xa0\\xe8\\xba\\xac\\xe5\\x8a\\xb3\\xe8\\xbf\\xb9\\xef\\xbc\\x8c\\xe9\\x87\\x8c\\xe4\\xb8\\x87\\xe6\\x80\\xa5\\xe4\\xba\\xad\\xe7\\x96\\x91'\n",
      "Epoch 82/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.0509\n",
      "b'          \\xe6\\x97\\xa2\\xe9\\x80\\x9a\\xe4\\xb8\\x87\\xe5\\xbe\\x80\\xe4\\xb8\\xba\\xef\\xbc\\x8c\\xe7\\xb4\\xa0\\xe5\\x85\\xb8\\xe6\\xb1\\xbe\\xe6\\x9c\\x88\\xe5\\x8c\\x96'\n",
      "Epoch 83/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.5125\n",
      "b'          \\xe4\\xb8\\xba\\xe8\\x90\\x8d\\xe7\\xbb\\xae\\xe7\\xba\\xb3\\xe4\\xb8\\xba\\xef\\xbc\\x8c\\xe5\\x88\\x91\\xe4\\xba\\x8e\\xe6\\x96\\xb9\\xe6\\x96\\xb9\\xe8\\xbd\\xbb'\n",
      "Epoch 84/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.1375\n",
      "b'          \\xe6\\x9c\\x88\\xe4\\xb8\\x87\\xe4\\xb8\\x87\\xe8\\xbf\\xb9\\xe9\\x80\\x9a\\xef\\xbc\\x8c\\xe6\\x82\\xa6\\xe5\\xb2\\x82\\xe5\\xbd\\xa2\\xe6\\x9c\\x88\\xe7\\x8e\\xb3'\n",
      "Epoch 85/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 14.6284\n",
      "b'          \\xe5\\xb8\\xad\\xe5\\xaf\\xb8\\xe5\\x85\\xb8\\xe5\\xbe\\x80\\xe4\\xb8\\xbe\\xef\\xbc\\x8c\\xe8\\xbd\\xbb\\xe5\\x80\\xa6\\xe9\\x98\\x85\\xe5\\xbf\\x83\\xe9\\x9b\\x95'\n",
      "Epoch 86/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 11.9038\n",
      "b'          \\xe5\\x8d\\xb1\\xe6\\x96\\xb9\\xe5\\x90\\xaf\\xe6\\xb1\\xa0\\xe9\\x9b\\xaa\\xef\\xbc\\x8c\\xe5\\xb9\\xbf\\xe5\\xb1\\x82\\xe7\\xaf\\x86\\xe9\\xa3\\x8e\\xe5\\xbf\\x98'\n",
      "Epoch 87/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 13.7926\n",
      "b'          \\xe6\\xbe\\x84\\xe4\\xb9\\x83\\xe6\\x80\\xa5\\xe6\\xac\\xa2\\xe6\\x98\\x8e\\xef\\xbc\\x8c\\xe5\\xb2\\x82\\xe5\\xa3\\xb0\\xe8\\xbd\\xbb\\xe6\\xad\\xa4\\xe5\\xbf\\x98'\n",
      "Epoch 88/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 11.7231\n",
      "b'          \\xe5\\xa3\\xb0\\xe6\\xa1\\xa5\\xe8\\xa7\\x82\\xe6\\x95\\xa3\\xe7\\x94\\xb5\\xef\\xbc\\x8c\\xe6\\x96\\x9c\\xe5\\x97\\xa3\\xe5\\xaf\\x9f\\xe5\\x8d\\x83\\xe5\\xbf\\x83'\n",
      "Epoch 89/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 11.1633\n",
      "b'          \\xe5\\x80\\xa6\\xe7\\x92\\xa7\\xe6\\xa0\\x91\\xe5\\xaf\\xbb\\xe5\\xb1\\x82\\xef\\xbc\\x8c\\xe4\\xb9\\xb1\\xe5\\x87\\xba\\xe6\\xbe\\x84\\xe6\\xad\\xa4\\xe6\\x98\\x8e'\n",
      "Epoch 90/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 13.0819\n",
      "b'          \\xe9\\x9b\\x95\\xe9\\xab\\x98\\xe7\\x9a\\x8e\\xe6\\x96\\xb9\\xe9\\xa9\\xac\\xef\\xbc\\x8c\\xe5\\x8d\\xb7\\xe9\\x81\\x93\\xe6\\x88\\x92\\xe7\\x8e\\x89\\xe8\\xbe\\x99'\n",
      "Epoch 91/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.8590\n",
      "b'          \\xe4\\xb9\\x83\\xe5\\x93\\x8d\\xe5\\xbe\\x80\\xe6\\xae\\xbf\\xe4\\xb8\\x8a\\xef\\xbc\\x8c\\xe6\\x82\\xa6\\xe9\\xa3\\x8e\\xe5\\x8f\\xaf\\xe4\\xba\\x8e\\xe9\\x99\\x88'\n",
      "Epoch 92/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 11.7471\n",
      "b'          \\xe4\\xbd\\x95\\xe5\\x85\\xb9\\xe7\\x96\\x91\\xe5\\x8a\\xb3\\xe7\\xbb\\xb3\\xef\\xbc\\x8c\\xe6\\xae\\xbd\\xe9\\x9b\\x95\\xe8\\x8a\\xb3\\xe8\\x8d\\xb7\\xe4\\xba\\x8e'\n",
      "Epoch 93/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.6517\n",
      "b'          \\xe5\\xb9\\xbf\\xe5\\x87\\xa4\\xe5\\xbc\\xa6\\xe7\\x8e\\x89\\xe7\\xbb\\xae\\xef\\xbc\\x8c\\xe6\\xae\\xbd\\xe6\\x89\\x80\\xe7\\xa2\\xa7\\xe7\\x95\\x99\\xe5\\x8d\\xb3'\n",
      "Epoch 94/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.2386\n",
      "b'          \\xe5\\x9d\\x9f\\xe6\\xb8\\x85\\xe6\\x8a\\xab\\xe9\\x9b\\xaa\\xe7\\x9a\\x8e\\xef\\xbc\\x8c\\xe5\\xa3\\xb0\\xe9\\x9a\\x90\\xe5\\xb2\\x82\\xe5\\x8d\\xb3\\xe7\\xaf\\x86'\n",
      "Epoch 95/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 13.5086\n",
      "b'          \\xe5\\xbe\\x85\\xe7\\xa2\\xa7\\xe5\\x8d\\x83\\xe6\\x98\\xad\\xe9\\xaa\\x8f\\xef\\xbc\\x8c\\xe6\\x8a\\xab\\xe7\\xa2\\xa7\\xe8\\x99\\x9a\\xe6\\xac\\xb9\\xe5\\xb8\\xad'\n",
      "Epoch 96/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 11.7920\n",
      "b'          \\xe6\\x8a\\xab\\xe5\\x8d\\xb1\\xe4\\xb8\\xba\\xe5\\xbf\\x98\\xe6\\xae\\xbd\\xef\\xbc\\x8c\\xe6\\x8a\\xab\\xe7\\x9b\\x88\\xe5\\xbf\\x98\\xe9\\xa3\\x8e\\xe8\\x82\\x86'\n",
      "Epoch 97/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.3181\n",
      "b'          \\xe5\\x9b\\xbe\\xe5\\x8c\\x96\\xe4\\xba\\x8e\\xe5\\x85\\xb9\\xe5\\x85\\xb0\\xef\\xbc\\x8c\\xe6\\xae\\xbd\\xe6\\xac\\xb9\\xe9\\xa3\\x8e\\xe6\\x98\\x8e\\xe8\\xba\\xac'\n",
      "Epoch 98/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.3254\n",
      "b'          \\xe5\\xbd\\xa2\\xe6\\x91\\x87\\xe8\\xb5\\x8f\\xe7\\x9a\\x8e\\xe4\\xb9\\x83\\xef\\xbc\\x8c\\xe7\\xb4\\xa0\\xe9\\x98\\xb4\\xe5\\x85\\xb9\\xe7\\x95\\x99\\xe5\\x86\\x99'\n",
      "Epoch 99/100\n",
      "109/109 [==============================] - 0s 1ms/step - loss: 12.5483\n",
      "b'          \\xe4\\xbd\\x95\\xe6\\x96\\x9c\\xe7\\xa7\\x91\\xe5\\xbf\\x98\\xe7\\xaf\\x86\\xef\\xbc\\x8c\\xe7\\xbb\\xae\\xe6\\x96\\xb9\\xe5\\x9d\\x9f\\xe5\\x85\\xb9\\xe5\\xbf\\x98'\n",
      "Epoch 100/100\n",
      "109/109 [==============================] - 0s 2ms/step - loss: 12.6241\n",
      "b'          \\xe7\\xa2\\xa7\\xe9\\xab\\x98\\xe6\\x95\\xa3\\xe6\\xb2\\xb3\\xe6\\x96\\xb9\\xef\\xbc\\x8c\\xe7\\x8e\\x89\\xe5\\x88\\x91\\xe7\\x96\\x91\\xe5\\xb2\\x82\\xe6\\xb1\\xa0'\n",
      "善池所披阴，坟亭卫多无\n",
      "绮馀酒盈倦，摇待忘清广\n",
      "声殿欹卫阙，人前泛如玉\n",
      "起阅急多忘，风玳雉此得\n",
      "耿察通雕危，往广处荡电\n",
      "碧急凝轻兹，酒清高处绮\n",
      "往得赏散电，刑池雉桥得\n",
      "披匣酒倦芳，皎声刑怀兹\n",
      "乃萍万绮上，日烟刑怀踪\n",
      "篆谏嗣阅凤，慎皎察通写\n",
      "桥卷急轻忘，必忘筵化昭\n",
      "间芳为科上，亭盈阙百迹\n",
      "罍绮于层殿，辙图陈方玉\n",
      "刑所疑乱风，烟彩殽韵科\n",
      "敷寻所神卫，郑写倦多危\n",
      "月流绮轻即，筵坟阙殿席\n",
      "日桥何美寻，清对马圃曲\n",
      "广斜阙澄美，忘万刑踪摇\n",
      "忘观危轻刑，陈忘兹接皎\n",
      "殽殿阁雉初，慎敷清耿明\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import re\n",
    "import codecs\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "\n",
    "n = 5 # 只抽取五言诗\n",
    "latent_dim = 64 # 隐变量维度\n",
    "hidden_dim = 64 # 隐层节点数\n",
    "\n",
    "## Preprocessor.get_shi()\n",
    "s = codecs.open('shi.txt', encoding='utf-8').read()\n",
    "# for i in s:\n",
    "#     print(i)\n",
    "# 通过正则表达式找出所有的五言诗\n",
    "#  re.compile(r'foo\\(.*?\\)')\n",
    "# s = re.findall(u'(.{%s}，.{%s}。.)\\r\\n'%(n,n), s)\n",
    "s = re.findall(u'([^]+)。([^]+)。\\n', s)\n",
    "# for i in s:\n",
    "#     print(i)\n",
    "shi = []\n",
    "for i in s:\n",
    "#     print(i)\n",
    "    for j in i.split(u'。'): # 按句切分\n",
    "        if j:\n",
    "            shi.append(j)\n",
    "\n",
    "shi = [i[:n] + i[n+1:] for i in shi if len(i) == 2*n+1]\n",
    "print(len(shi))\n",
    "print(len(s))\n",
    "\n",
    "## Preprocessor.get_vocab()\n",
    "# 构建字与id的相互映射\n",
    "id2char = dict(enumerate(set(''.join(shi))))\n",
    "char2id = {j:i for i,j in id2char.items()}\n",
    "print(f'length {len(id2char)}')\n",
    "embedding_len = len(id2char)\n",
    "\n",
    "# 诗歌id化\n",
    "shi2id = [[char2id[j] for j in i] for i in shi]\n",
    "shi2id = np.array(shi2id)\n",
    "\n",
    "# Normolization\n",
    "# print(type(shi2id[0][0]))\n",
    "# Normalizing the images to the range of [0., 1.]\n",
    "# shi2id /= embedding_len\n",
    "# shi2id /= embedding_len\n",
    "\n",
    "print(type(shi2id[0][0]))\n",
    "\n",
    "# # Binarization\n",
    "# train_images[train_images >= .5] = 1.\n",
    "# train_images[train_images < .5] = 0.\n",
    "# test_images[test_images >= .5] = 1.\n",
    "# test_images[test_images < .5] = 0.\n",
    "\n",
    "# no flow control\n",
    "class GCNN(Layer): # 定义GCNN层，结合残差\n",
    "    def __init__(self, output_dim=None, residual=False, **kwargs):\n",
    "        super(GCNN, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.residual = residual\n",
    "    def build(self, input_shape):\n",
    "        if self.output_dim == None:\n",
    "            self.output_dim = input_shape[-1]\n",
    "        self.kernel = self.add_weight(name='gcnn_kernel',\n",
    "                                     shape=(3, input_shape[-1],\n",
    "                                            self.output_dim * 2),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "    def call(self, x):\n",
    "        _ = K.conv1d(x, self.kernel, padding='same')\n",
    "        _ = _[:,:,:self.output_dim] * K.sigmoid(_[:,:,self.output_dim:])\n",
    "        if self.residual:\n",
    "            return _ + x\n",
    "        else:\n",
    "            return _\n",
    "\n",
    "## model.VAEModel\n",
    "input_sentence = Input(shape=(2*n,), dtype='int32')\n",
    "input_vec = Embedding(embedding_len, hidden_dim)(input_sentence) # id转向量\n",
    "h = GCNN(residual=True)(input_vec) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GCNN(residual=True)(h) # GCNN层\n",
    "h = GlobalAveragePooling1D()(h) # 池化\n",
    "\n",
    "# 算均值方差\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "## modules.sampling\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0, stddev=1)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "z = Lambda(sampling)([z_mean, z_log_var])\n",
    "\n",
    "# 定义解码层，分开定义是为了后面的重用\n",
    "decoder_hidden = Dense(hidden_dim*(2*n))\n",
    "decoder_cnn = GCNN(residual=True)\n",
    "decoder_dense = Dense(len(char2id), activation='softmax')\n",
    "\n",
    "h = decoder_hidden(z)\n",
    "h = Reshape((2*n, hidden_dim))(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "h = decoder_cnn(h)\n",
    "output = decoder_dense(h)\n",
    "\n",
    "\n",
    "# 建立模型\n",
    "vae = Model(input_sentence, output)\n",
    "\n",
    "# xent_loss是重构loss，kl_loss是KL loss\n",
    "xent_loss = K.sum(K.sparse_categorical_crossentropy(input_sentence, output), 1)\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "# add_loss是新增的方法，用于更灵活地添加各种loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "vae.summary()\n",
    "\n",
    "# 重用解码层，构建单独的生成模型\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_ = decoder_hidden(decoder_input)\n",
    "_ = Reshape((2*n, hidden_dim))(_)\n",
    "_ = decoder_cnn(_)\n",
    "_output = decoder_dense(_)\n",
    "generator = Model(decoder_input, _output)\n",
    "\n",
    "\n",
    "# 利用生成模型随机生成一首诗\n",
    "def gen():\n",
    "    r = generator.predict(np.random.randn(1, latent_dim))[0]\n",
    "    r = r.argmax(axis=1)\n",
    "    return ''.join([id2char[i] for i in r[:n]])\\\n",
    "           + u'，'\\\n",
    "           + ''.join([id2char[i] for i in r[n:]])\n",
    "\n",
    "\n",
    "# 回调器，方便在训练过程中输出\n",
    "class Evaluate(Callback):\n",
    "    def __init__(self):\n",
    "        self.log = []\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.log.append(gen())\n",
    "        print( (u'          %s'%(self.log[-1])).encode('utf-8') )\n",
    "\n",
    "\n",
    "evaluator = Evaluate()\n",
    "\n",
    "vae.fit(shi2id,\n",
    "        shuffle=True,\n",
    "        epochs=100,\n",
    "        batch_size=64,\n",
    "        callbacks=[evaluator])\n",
    "\n",
    "vae.save_weights('shi.model')\n",
    "\n",
    "for i in range(20):\n",
    "    print(gen())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
